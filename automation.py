import subprocess

# Define a list of arguments to use
arguments_list = [
    # [
    #             "--data_dir","./train_data_conll - Copy",
    #             "--labels","./labels.txt",
    #             "--model_name_or_path","./distilBERT-Sprachbildung",
    #             "--output_dir","./train_data_conll - Copy/regularized",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased"
    #    ]
    # [
    #             "--data_dir","./filtered_train_data_conll",
    #             "--labels","./labels.txt",
    #             "--model_name_or_path","./distilBERT-Sprachbildung",
    #             "--output_dir","./filtered_train_data_conll/regularized",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased"
    #    ],
    # [
    #             "--data_dir","./sc_train_data_conll",
    #             "--labels","./labels.txt",
    #             "--model_name_or_path","./distilBERT-Sprachbildung",
    #             "--output_dir","./sc_train_data_conll/regularized",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased"
    #    ],
    #    [
    #             "--data_dir","./sCR_train_data_conll",
    #             "--labels","./labels.txt",
    #             "--model_name_or_path","./distilBERT-Sprachbildung",
    #             "--output_dir","./sCR_train_data_conll/regularized",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False"
    #    ],
    #    [
    #             "--data_dir","./sCRD_train_data_conll",
    #             "--labels","./labels.txt",
    #             "--model_name_or_path","./distilBERT-Sprachbildung",
    #             "--output_dir","./sCRD_train_data_conll/regularized",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False"
    #    ],
    #    [
    #             "--data_dir","./BIO/nsCRD_train_data_conll",
    #             "--labels","./labels.txt",
    #             "--model_name_or_path","./distilBERT-Sprachbildung",
    #             "--output_dir","./nsCRD_train_data_conll/regularized",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased"
    #    ]
    #    [
    #             "--data_dir","./bus_train_data_conll",
    #             "--labels","./labels.txt",
    #             "--model_name_or_path","./distilBERT-Sprachbildung",
    #             "--output_dir","./bus_train_data_conll/regularized",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased"
    #    ]
    #    [
    #             "--data_dir","./sr_augmented_train_data_conll",
    #             "--labels","./labels.txt",
    #             "--model_name_or_path","./distilBERT-Sprachbildung",
    #             "--output_dir","./sr_augmented_train_data_conll/regularized",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased"
    #    ],
    #    [
    #             "--data_dir","./sis_augmented_train_data_conll",
    #             "--labels","./labels.txt",
    #             "--model_name_or_path","./distilBERT-Sprachbildung",
    #             "--output_dir","./sis_augmented_train_data_conll/regularized",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased"
    #    ]
    #    [
    #             "--data_dir","./lwtr_augmented_train_data_conll",
    #             "--labels","./labels.txt",
    #             "--model_name_or_path","./distilBERT-Sprachbildung",
    #             "--output_dir","./lwtr_augmented_train_data_conll/regularized",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False"
    #    ],
    #    [
    #             "--data_dir","./mr_augmented_train_data_conll",
    #             "--labels","./labels.txt",
    #             "--model_name_or_path","./distilBERT-Sprachbildung",
    #             "--output_dir","./mr_augmented_train_data_conll/regularized",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False"
    #    ]
    # Add more argument sets as needed
    #   NON_BIO
    # [
    #             "--data_dir","./NON_BIO/new_2_train_data_conll_non_bio",
    #             "--labels","./labels_non_bio.txt",
    #             "--model_name_or_path","./distilBERT_Sprachbildung",
    #             "--output_dir","./NON_BIO/new_2_train_data_conll_non_bio/regularized_with_optimizer",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased"
    #    ],
    #    [
    #             "--data_dir","./NON_BIO/sr_augmented_new_2_train_data_conll_non_bio",
    #             "--labels","./labels_non_bio.txt",
    #             "--model_name_or_path","./distilBERT_Sprachbildung",
    #             "--output_dir","./NON_BIO/sr_augmented_new_2_train_data_conll_non_bio/regularized_with_optimizer",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased"
    #    ],
    #    [
    #             "--data_dir","./NON_BIO/sc_new_2_train_data_conll_non_bio",
    #             "--labels","./labels_non_bio.txt",
    #             "--model_name_or_path","./distilBERT_Sprachbildung",
    #             "--output_dir","./NON_BIO/sc_new_2_train_data_conll_non_bio/regularized_with_optimizer",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased"
    #    ]
    #    [
    #             "--data_dir","./NON_BIO/bus_new_2_train_data_conll_non_bio",
    #             "--labels","./labels_non_bio.txt",
    #             "--model_name_or_path","./distilBERT_Sprachbildung",
    #             "--output_dir","./NON_BIO/bus_new_2_train_data_conll_non_bio/regularized_with_optimizer",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased"
    #    ]
    #  [
    #             "--data_dir","./NON_BIO/new_2_train_data_conll_non_bio",
    #             "--labels","./labels_non_bio.txt",
    #             "--model_name_or_path","./distilBERT_Sprachbildung",
    #             "--output_dir","./NON_BIO/new_2_train_data_conll_non_bio/regularized_with_optimizer_4_epoch",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","4",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased"
    #    ],
    #    [
    #             "--data_dir","./NON_BIO/sr_augmented_new_2_train_data_conll_non_bio",
    #             "--labels","./labels_non_bio.txt",
    #             "--model_name_or_path","./distilBERT_Sprachbildung",
    #             "--output_dir","./NON_BIO/sr_augmented_new_2_train_data_conll_non_bio/regularized_with_optimizer_4_epoch",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","4",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased"
    #    ],
    #    [
    #             "--data_dir","./NON_BIO/sc_new_2_train_data_conll_non_bio",
    #             "--labels","./labels_non_bio.txt",
    #             "--model_name_or_path","./distilBERT_Sprachbildung",
    #             "--output_dir","./NON_BIO/sc_new_2_train_data_conll_non_bio/regularized_with_optimizer_4_epoch",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","4",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased"
    #    ],
    #    [
    #             "--data_dir","./NON_BIO/bus_new_2_train_data_conll_non_bio",
    #             "--labels","./labels_non_bio.txt",
    #             "--model_name_or_path","./distilBERT_Sprachbildung",
    #             "--output_dir","./NON_BIO/bus_new_2_train_data_conll_non_bio/regularized_with_optimizer_4_epoch",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","4",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased"
    #    ]
       # BIO
       [
                "--data_dir","./BIO/sr_augmented_new_2_train_data_conll",
                "--labels","./labels.txt",
                "--model_name_or_path","./distilBERT_Sprachbildung",
                "--output_dir","./BIO/sr_augmented_new_2_train_data_conll/regularized_with_optimizer",
                "--max_seq_length","128",
                "--num_train_epochs","35",
                "--per_device_train_batch_size","16",
                "--per_device_eval_batch_size","16",
                "--save_steps","-1",
                "--seed","1",
                "--warmup_steps","5000",
                "--smooth","100",
                "--lambda_val","0.03",
                "--is_pmi",
                "--is_subword",
                "--do_train",
                "--do_eval",
                "--do_predict", "True",
                "--wandb_name","check",
                "--overwrite_output_dir",
                "--dataloader_pin_memory","False",
                "--tokenizer_name","distilbert-base-german-cased",
                "--testing", "False",
                "--tagset","./tagset.txt"
       ]
    #    [
    #             "--data_dir","./BIO/new_2_train_data_conll",
    #             "--labels","./labels.txt",
    #             "--model_name_or_path","./distilBERT_Sprachbildung",
    #             "--output_dir","./BIO/new_2_train_data_conll/regularized_with_optimizer",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased"
    #    ]
    #    [
    #             "--data_dir","./BIO/bus_new_2_train_data_conll",
    #             "--labels","./labels.txt",
    #             "--model_name_or_path","./distilBERT_Sprachbildung",
    #             "--output_dir","./BIO/bus_new_2_train_data_conll/regularized_with_optimizer",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased"
    #    ]
    #       [
    #             "--data_dir","./BIO/sc_new_2_train_data_conll",
    #             "--labels","./labels.txt",
    #             "--model_name_or_path","./distilBERT_Sprachbildung",
    #             "--output_dir","./BIO/sc_new_2_train_data_conll/regularized_with_optimizer",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased"
    #    ]


    #Testing NON BIO
    # [
    #             "--data_dir","./NON_BIO/new_2_train_data_conll_non_bio",
    #             "--labels","./labels_non_bio.txt",
    #             "--model_name_or_path","./NON_BIO/new_2_train_data_conll_non_bio/regularized_with_optimizer",
    #             "--output_dir","./NON_BIO/new_2_train_data_conll_non_bio/regularized_with_optimizer",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased",
    #             "--testing","True",
    #             "--tagset", "./tagset-1.txt"
    #    ],
    #    [
    #             "--data_dir","./NON_BIO/sr_augmented_new_2_train_data_conll_non_bio",
    #             "--labels","./labels_non_bio.txt",
    #             "--model_name_or_path","./NON_BIO/sr_augmented_new_2_train_data_conll_non_bio/regularized_with_optimizer",
    #             "--output_dir","./NON_BIO/sr_augmented_new_2_train_data_conll_non_bio/regularized_with_optimizer",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased",
    #             "--testing","True",
    #             "--tagset", "./tagset-2.txt"
    #    ],
    #    [
    #             "--data_dir","./NON_BIO/bus_new_2_train_data_conll_non_bio",
    #             "--labels","./labels_non_bio.txt",
    #             "--model_name_or_path","./NON_BIO/bus_new_2_train_data_conll_non_bio/regularized_with_optimizer",
    #             "--output_dir","./NON_BIO/bus_new_2_train_data_conll_non_bio/regularized_with_optimizer",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased",
    #             "--testing","True",
    #             "--tagset","./tagset-2.txt"
    #    ],
    #    [
    #             "--data_dir","./NON_BIO/sc_new_2_train_data_conll_non_bio",
    #             "--labels","./labels_non_bio.txt",
    #             "--model_name_or_path","./NON_BIO/sc_new_2_train_data_conll_non_bio/regularized_with_optimizer",
    #             "--output_dir","./NON_BIO/sc_new_2_train_data_conll_non_bio/regularized_with_optimizer",
    #             "--max_seq_length","128",
    #             "--num_train_epochs","35",
    #             "--per_device_train_batch_size","16",
    #             "--per_device_eval_batch_size","16",
    #             "--save_steps","-1",
    #             "--seed","1",
    #             "--warmup_steps","5000",
    #             "--smooth","100",
    #             "--lambda_val","0.03",
    #             "--is_pmi",
    #             "--is_subword",
    #             "--do_train",
    #             "--do_eval",
    #             "--do_predict", "True",
    #             "--wandb_name","check",
    #             "--overwrite_output_dir",
    #             "--dataloader_pin_memory","False",
    #             "--tokenizer_name","distilbert-base-german-cased",
    #             "--testing","True",
    #             "--tagset","./tagset-2.txt"
    #    ]

    #Testing BIO
      #  [
      #           "--data_dir","./BIO/sr_augmented_new_2_train_data_conll",
      #           "--labels","./labels.txt",
      #           "--model_name_or_path","./BIO/sr_augmented_new_2_train_data_conll/regularized_with_optimizer",
      #           "--output_dir","./BIO/sr_augmented_new_2_train_data_conll/regularized_with_optimizer",
      #           "--max_seq_length","128",
      #           "--num_train_epochs","35",
      #           "--per_device_train_batch_size","16",
      #           "--per_device_eval_batch_size","16",
      #           "--save_steps","-1",
      #           "--seed","1",
      #           "--warmup_steps","5000",
      #           "--smooth","100",
      #           "--lambda_val","0.03",
      #           "--is_pmi",
      #           "--is_subword",
      #           "--do_train",
      #           "--do_eval",
      #           "--do_predict", "True",
      #           "--wandb_name","check",
      #           "--overwrite_output_dir",
      #           "--dataloader_pin_memory","False",
      #           "--tokenizer_name","distilbert-base-german-cased",
      #           "--testing", "True",
      #           "--tagset","./tagset.txt"
      #  ]
      #  [
      #           "--data_dir","./BIO/new_2_train_data_conll",
      #           "--labels","./labels.txt",
      #           "--model_name_or_path","./BIO/new_2_train_data_conll/regularized_with_optimizer",
      #           "--output_dir","./BIO/new_2_train_data_conll/regularized_with_optimizer",
      #           "--max_seq_length","128",
      #           "--num_train_epochs","35",
      #           "--per_device_train_batch_size","16",
      #           "--per_device_eval_batch_size","16",
      #           "--save_steps","-1",
      #           "--seed","1",
      #           "--warmup_steps","5000",
      #           "--smooth","100",
      #           "--lambda_val","0.03",
      #           "--is_pmi",
      #           "--is_subword",
      #           "--do_train",
      #           "--do_eval",
      #           "--do_predict", "True",
      #           "--wandb_name","check",
      #           "--overwrite_output_dir",
      #           "--dataloader_pin_memory","False",
      #           "--tokenizer_name","distilbert-base-german-cased",
      #           "--testing", "True",
      #           "--tagset","./tagset.txt"
      #  ],
      #  [
      #           "--data_dir","./BIO/bus_new_2_train_data_conll",
      #           "--labels","./labels.txt",
      #           "--model_name_or_path","./BIO/bus_new_2_train_data_conll/regularized_with_optimizer",
      #           "--output_dir","./BIO/bus_new_2_train_data_conll/regularized_with_optimizer",
      #           "--max_seq_length","128",
      #           "--num_train_epochs","35",
      #           "--per_device_train_batch_size","16",
      #           "--per_device_eval_batch_size","16",
      #           "--save_steps","-1",
      #           "--seed","1",
      #           "--warmup_steps","5000",
      #           "--smooth","100",
      #           "--lambda_val","0.03",
      #           "--is_pmi",
      #           "--is_subword",
      #           "--do_train",
      #           "--do_eval",
      #           "--do_predict", "True",
      #           "--wandb_name","check",
      #           "--overwrite_output_dir",
      #           "--dataloader_pin_memory","False",
      #           "--tokenizer_name","distilbert-base-german-cased",
      #           "--testing", "True",
      #           "--tagset","./tagset.txt"
      #  ],
      #   [
      #           "--data_dir","./BIO/sc_new_2_train_data_conll",
      #           "--labels","./labels.txt",
      #           "--model_name_or_path","./BIO/sc_new_2_train_data_conll/regularized_with_optimizer",
      #           "--output_dir","./BIO/sc_new_2_train_data_conll/regularized_with_optimizer",
      #           "--max_seq_length","128",
      #           "--num_train_epochs","35",
      #           "--per_device_train_batch_size","16",
      #           "--per_device_eval_batch_size","16",
      #           "--save_steps","-1",
      #           "--seed","1",
      #           "--warmup_steps","5000",
      #           "--smooth","100",
      #           "--lambda_val","0.03",
      #           "--is_pmi",
      #           "--is_subword",
      #           "--do_train",
      #           "--do_eval",
      #           "--do_predict", "True",
      #           "--wandb_name","check",
      #           "--overwrite_output_dir",
      #           "--dataloader_pin_memory","False",
      #           "--tokenizer_name","distilbert-base-german-cased",
      #           "--testing", "True",
      #           "--tagset","./tagset.txt"
      #  ]

      #Predicting NON_BIO
      # [
      #           "--data_dir","./NON_BIO/new_2_train_data_conll_non_bio",
      #           "--labels","./labels_non_bio.txt",
      #           "--model_name_or_path","./NON_BIO/new_2_train_data_conll_non_bio/regularized_with_optimizer",
      #           "--output_dir","./NON_BIO/new_2_train_data_conll_non_bio/regularized_with_optimizer",
      #           "--max_seq_length","128",
      #           "--num_train_epochs","35",
      #           "--per_device_train_batch_size","16",
      #           "--per_device_eval_batch_size","16",
      #           "--save_steps","-1",
      #           "--seed","1",
      #           "--warmup_steps","5000",
      #           "--smooth","100",
      #           "--lambda_val","0.03",
      #           "--is_pmi",
      #           "--is_subword",
      #           "--do_train",
      #           "--do_eval",
      #           "--do_predict", "True",
      #           "--wandb_name","check",
      #           "--overwrite_output_dir",
      #           "--dataloader_pin_memory","False",
      #           "--tokenizer_name","distilbert-base-german-cased",
      #           "--testing","True",
      #           "--tagset", "./tagset-1.txt",
      #           "--sentence_to_predict", "= = = = = Teacher_feedback = = = = = insgesamt : ich halten ihr Analyse für gut gelingen , allerdings sein mir der Punkt der Sprachproduktion noch etwas untergehen , gerade bei der Aufgabe , der schon ein Diskursfunktion enthalten müssen auch überlegen werden , wie ein Lösung hier aussehen können ( = der Sprachprodukt ) und dann auch überlegen werden , welche sprachlich Mittel darin ein Hürde darstellen und irgendwie spät bei der Unterrichtsplanung als Sprachhilfe einbauen werden sollen . der Punkt der Sprachproduktion haben sie nicht vollständig ausführen ."
      #  ]
       #Predicting BIO
      #  [
      #           "--data_dir","./BIO/new_2_train_data_conll",
      #           "--labels","./labels.txt",
      #           "--model_name_or_path","./BIO/new_2_train_data_conll/regularized_with_optimizer",
      #           "--output_dir","./BIO/new_2_train_data_conll/regularized_with_optimizer",
      #           "--max_seq_length","128",
      #           "--num_train_epochs","35",
      #           "--per_device_train_batch_size","16",
      #           "--per_device_eval_batch_size","16",
      #           "--save_steps","-1",
      #           "--seed","1",
      #           "--warmup_steps","5000",
      #           "--smooth","100",
      #           "--lambda_val","0.03",
      #           "--is_pmi",
      #           "--is_subword",
      #           "--do_train",
      #           "--do_eval",
      #           "--do_predict", "True",
      #           "--wandb_name","check",
      #           "--overwrite_output_dir",
      #           "--dataloader_pin_memory","False",
      #           "--tokenizer_name","distilbert-base-german-cased",
      #           "--testing","True",
      #           "--tagset", "./tagset.txt",
      #           "--sentence_to_predict", "= = = = = Teacher_feedback = = = = = insgesamt : ich halten ihr Analyse für gut gelingen , allerdings sein mir der Punkt der Sprachproduktion noch etwas untergehen , gerade bei der Aufgabe , der schon ein Diskursfunktion enthalten müssen auch überlegen werden , wie ein Lösung hier aussehen können ( = der Sprachprodukt ) und dann auch überlegen werden , welche sprachlich Mittel darin ein Hürde darstellen und irgendwie spät bei der Unterrichtsplanung als Sprachhilfe einbauen werden sollen . der Punkt der Sprachproduktion haben sie nicht vollständig ausführen ."
      #  ]

]

# Loop through the arguments and run your main script
for args in arguments_list:
    cmd = ["python", "run_ner.py"] + args
    subprocess.run(cmd)
